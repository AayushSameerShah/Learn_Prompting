"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[170],{3905:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>u});var t=n(7294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function o(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function i(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?o(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function s(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=t.createContext({}),f=function(e){var a=t.useContext(l),n=a;return e&&(n="function"==typeof e?e(a):i(i({},a),e)),n},p=function(e){var a=f(e.components);return t.createElement(l.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},h=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),h=f(n),u=r,d=h["".concat(l,".").concat(u)]||h[u]||m[u]||o;return n?t.createElement(d,i(i({ref:a},p),{},{components:n})):t.createElement(d,i({ref:a},p))}));function u(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=h;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var f=2;f<o;f++)i[f]=n[f];return t.createElement.apply(null,i)}return t.createElement.apply(null,n)}h.displayName="MDXCreateElement"},8363:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>f});var t=n(7462),r=(n(7294),n(3905));const o={sidebar_position:1e3},i="Bibliography",s={unversionedId:"bibliography",id:"bibliography",title:"Bibliography",description:"The page contains an organized list of all papers used by this course.",source:"@site/docs/bibliography.md",sourceDirName:".",slug:"/bibliography",permalink:"/promptgineering/docs/bibliography",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v0.0.2/docs/bibliography.md",tags:[],version:"current",sidebarPosition:1e3,frontMatter:{sidebar_position:1e3},sidebar:"tutorialSidebar",previous:{title:"ReAct",permalink:"/promptgineering/docs/advanced_applications/react"}},l={},f=[{value:"Prompt Engineering Strategies",id:"prompt-engineering-strategies",level:2},{value:"Chain of Thought(@wei2022chain) \ud83d\udd35",id:"chain-of-thoughtwei2022chain-",level:4},{value:"Zero Shot Chain of Thought(@kojima2022large) \ud83d\udd35",id:"zero-shot-chain-of-thoughtkojima2022large-",level:4},{value:"Self Consistency(@wang2022selfconsistency) \ud83d\udd35",id:"self-consistencywang2022selfconsistency-",level:4},{value:"What Makes Good In-Context Examples for GPT-3?(@liu2021makes) \ud83d\udd35",id:"what-makes-good-in-context-examples-for-gpt-3liu2021makes-",level:4},{value:"Generated Knowledge(@liu2021generated) \ud83d\udd35",id:"generated-knowledgeliu2021generated-",level:4},{value:"Rethinking the role of demonstrations(@min2022rethinking) \ud83d\udd35",id:"rethinking-the-role-of-demonstrationsmin2022rethinking-",level:4},{value:"Scratchpads(@nye2021work)",id:"scratchpadsnye2021work",level:4},{value:"Reliability",id:"reliability",level:2},{value:"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning(@ye2022unreliability) \ud83d\udd35",id:"the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-",level:4},{value:"Prompting GPT-3 to be reliable(@si2022prompting)",id:"prompting-gpt-3-to-be-reliablesi2022prompting",level:4},{value:"Diverse Prompts(@li2022advance)",id:"diverse-promptsli2022advance",level:4},{value:"Problems with biases(@zhao2021calibrate)",id:"problems-with-biaseszhao2021calibrate",level:4},{value:"Enhanced Self Consistency(@mitchell2022enhancing)",id:"enhanced-self-consistencymitchell2022enhancing",level:4},{value:"Automated Prompt Engineering",id:"automated-prompt-engineering",level:2},{value:"AutoPrompt(@shin2020autoprompt) \ud83d\udd35",id:"autopromptshin2020autoprompt-",level:4},{value:"Automatic Prompt Engineer(@zhou2022large)",id:"automatic-prompt-engineerzhou2022large",level:4},{value:"Models",id:"models",level:2},{value:"Language Models",id:"language-models",level:3},{value:"GPT-3(@brown2020language) \ud83d\udd35",id:"gpt-3brown2020language-",level:4},{value:"GPT-3 Instruct(@ouyang2022training) \ud83d\udd35",id:"gpt-3-instructouyang2022training-",level:4},{value:"PaLM(@chowdhery2022palm) \ud83d\udd35",id:"palmchowdhery2022palm-",level:4},{value:"BLOOM(@scao2022bloom) \ud83d\udd35",id:"bloomscao2022bloom-",level:4},{value:"Jurassic 1(@lieberjurassic) \ud83d\udd35",id:"jurassic-1lieberjurassic-",level:4},{value:"Image Models",id:"image-models",level:3},{value:"Stable Diffusion(@rombach2021highresolution) \ud83d\udd35",id:"stable-diffusionrombach2021highresolution-",level:4},{value:"DALLE(@ramesh2022hierarchical) \ud83d\udd35",id:"dalleramesh2022hierarchical-",level:4},{value:"Soft Prompting",id:"soft-prompting",level:2},{value:"Soft Prompting(@lester2021power)",id:"soft-promptinglester2021power",level:4},{value:"Interpretable Discretized Soft Prompts(@khashabi2021prompt)",id:"interpretable-discretized-soft-promptskhashabi2021prompt",level:4},{value:"Datasets",id:"datasets",level:2},{value:"GSM8K(@cobbe2021training) \ud83d\udd35",id:"gsm8kcobbe2021training-",level:4},{value:"HotPotQA(@yang2018hotpotqa) \ud83d\udd35",id:"hotpotqayang2018hotpotqa-",level:4},{value:"Fever(@thorne2018fever) \ud83d\udd35",id:"feverthorne2018fever-",level:4},{value:"Image Prompt Engineering",id:"image-prompt-engineering",level:2},{value:"Taxonomy of prompt modifiers(@oppenlaender2022taxonomy)",id:"taxonomy-of-prompt-modifiersoppenlaender2022taxonomy",level:4},{value:"DiffusionDB(@wang2022diffusiondb)",id:"diffusiondbwang2022diffusiondb",level:4},{value:"Prompt Engineering IDEs",id:"prompt-engineering-ides",level:2},{value:"Prompt IDE(@strobelt2022promptide) \ud83d\udd35",id:"prompt-idestrobelt2022promptide-",level:4},{value:"Prompt Source(@bach2022promptsource) \ud83d\udd35",id:"prompt-sourcebach2022promptsource-",level:4},{value:"Applied Prompt Engineering",id:"applied-prompt-engineering",level:2},{value:"Language Model Cascades(@dohan2022language)",id:"language-model-cascadesdohan2022language",level:4},{value:"MRKL(@karpas2022mrkl) \ud83d\udd35",id:"mrklkarpas2022mrkl-",level:4},{value:"ReAct(@yao2022react) \ud83d\udd35",id:"reactyao2022react-",level:4},{value:"User Interface Design",id:"user-interface-design",level:2},{value:"Design Guidelines for Prompt Engineering Text-to-Image Generative Models(@liu2022design)",id:"design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design",level:4},{value:"Prompt Injection",id:"prompt-injection",level:2},{value:"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods(@crothers2022machine)",id:"machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine",level:4},{value:"Surveys",id:"surveys",level:2},{value:"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing(@liu2021pretrain)",id:"pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain",level:4},{value:"Miscl",id:"miscl",level:2},{value:"Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models(@bursztyn2022learning)",id:"learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning",level:4},{value:"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks(@wang2022supernaturalinstructions)",id:"super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions",level:4},{value:"Making Pre-trained Language Models Better Few-shot Learners(@gao2021making)",id:"making-pre-trained-language-models-better-few-shot-learnersgao2021making",level:4},{value:"Grounding with search results(@livin2022large)",id:"grounding-with-search-resultslivin2022large",level:4},{value:"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models(@dang2022prompt)",id:"how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt",level:4}],p={toc:f};function m(e){let{components:a,...n}=e;return(0,r.kt)("wrapper",(0,t.Z)({},p,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"bibliography"},"Bibliography"),(0,r.kt)("p",null,"The page contains an organized list of all papers used by this course.\nThe papers are organized by topic."),(0,r.kt)("p",null,"\ud83d\udd35 = Paper directly cited in this course. Other papers have informed my understanding of the topic."),(0,r.kt)("h2",{id:"prompt-engineering-strategies"},"Prompt Engineering Strategies"),(0,r.kt)("h4",{id:"chain-of-thoughtwei2022chain-"},"Chain of Thought",(0,r.kt)("sup",{parentName:"h4",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"zero-shot-chain-of-thoughtkojima2022large-"},"Zero Shot Chain of Thought",(0,r.kt)("sup",{parentName:"h4",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"self-consistencywang2022selfconsistency-"},"Self Consistency",(0,r.kt)("sup",{parentName:"h4",id:"fnref-3"},(0,r.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"what-makes-good-in-context-examples-for-gpt-3liu2021makes-"},"What Makes Good In-Context Examples for GPT-3?",(0,r.kt)("sup",{parentName:"h4",id:"fnref-4"},(0,r.kt)("a",{parentName:"sup",href:"#fn-4",className:"footnote-ref"},"4"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"generated-knowledgeliu2021generated-"},"Generated Knowledge",(0,r.kt)("sup",{parentName:"h4",id:"fnref-5"},(0,r.kt)("a",{parentName:"sup",href:"#fn-5",className:"footnote-ref"},"5"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"rethinking-the-role-of-demonstrationsmin2022rethinking-"},"Rethinking the role of demonstrations",(0,r.kt)("sup",{parentName:"h4",id:"fnref-6"},(0,r.kt)("a",{parentName:"sup",href:"#fn-6",className:"footnote-ref"},"6"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"scratchpadsnye2021work"},"Scratchpads",(0,r.kt)("sup",{parentName:"h4",id:"fnref-7"},(0,r.kt)("a",{parentName:"sup",href:"#fn-7",className:"footnote-ref"},"7"))),(0,r.kt)("h2",{id:"reliability"},"Reliability"),(0,r.kt)("h4",{id:"the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability-"},"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning",(0,r.kt)("sup",{parentName:"h4",id:"fnref-8"},(0,r.kt)("a",{parentName:"sup",href:"#fn-8",className:"footnote-ref"},"8"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"prompting-gpt-3-to-be-reliablesi2022prompting"},"Prompting GPT-3 to be reliable",(0,r.kt)("sup",{parentName:"h4",id:"fnref-9"},(0,r.kt)("a",{parentName:"sup",href:"#fn-9",className:"footnote-ref"},"9"))),(0,r.kt)("h4",{id:"diverse-promptsli2022advance"},"Diverse Prompts",(0,r.kt)("sup",{parentName:"h4",id:"fnref-10"},(0,r.kt)("a",{parentName:"sup",href:"#fn-10",className:"footnote-ref"},"10"))),(0,r.kt)("h4",{id:"problems-with-biaseszhao2021calibrate"},"Problems with biases",(0,r.kt)("sup",{parentName:"h4",id:"fnref-11"},(0,r.kt)("a",{parentName:"sup",href:"#fn-11",className:"footnote-ref"},"11"))),(0,r.kt)("h4",{id:"enhanced-self-consistencymitchell2022enhancing"},"Enhanced Self Consistency",(0,r.kt)("sup",{parentName:"h4",id:"fnref-12"},(0,r.kt)("a",{parentName:"sup",href:"#fn-12",className:"footnote-ref"},"12"))),(0,r.kt)("h2",{id:"automated-prompt-engineering"},"Automated Prompt Engineering"),(0,r.kt)("h4",{id:"autopromptshin2020autoprompt-"},"AutoPrompt",(0,r.kt)("sup",{parentName:"h4",id:"fnref-13"},(0,r.kt)("a",{parentName:"sup",href:"#fn-13",className:"footnote-ref"},"13"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"automatic-prompt-engineerzhou2022large"},"Automatic Prompt Engineer",(0,r.kt)("sup",{parentName:"h4",id:"fnref-14"},(0,r.kt)("a",{parentName:"sup",href:"#fn-14",className:"footnote-ref"},"14"))),(0,r.kt)("h2",{id:"models"},"Models"),(0,r.kt)("h3",{id:"language-models"},"Language Models"),(0,r.kt)("h4",{id:"gpt-3brown2020language-"},"GPT-3",(0,r.kt)("sup",{parentName:"h4",id:"fnref-15"},(0,r.kt)("a",{parentName:"sup",href:"#fn-15",className:"footnote-ref"},"15"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"gpt-3-instructouyang2022training-"},"GPT-3 Instruct",(0,r.kt)("sup",{parentName:"h4",id:"fnref-16"},(0,r.kt)("a",{parentName:"sup",href:"#fn-16",className:"footnote-ref"},"16"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"palmchowdhery2022palm-"},"PaLM",(0,r.kt)("sup",{parentName:"h4",id:"fnref-17"},(0,r.kt)("a",{parentName:"sup",href:"#fn-17",className:"footnote-ref"},"17"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"bloomscao2022bloom-"},"BLOOM",(0,r.kt)("sup",{parentName:"h4",id:"fnref-18"},(0,r.kt)("a",{parentName:"sup",href:"#fn-18",className:"footnote-ref"},"18"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"jurassic-1lieberjurassic-"},"Jurassic 1",(0,r.kt)("sup",{parentName:"h4",id:"fnref-19"},(0,r.kt)("a",{parentName:"sup",href:"#fn-19",className:"footnote-ref"},"19"))," \ud83d\udd35"),(0,r.kt)("h3",{id:"image-models"},"Image Models"),(0,r.kt)("h4",{id:"stable-diffusionrombach2021highresolution-"},"Stable Diffusion",(0,r.kt)("sup",{parentName:"h4",id:"fnref-20"},(0,r.kt)("a",{parentName:"sup",href:"#fn-20",className:"footnote-ref"},"20"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"dalleramesh2022hierarchical-"},"DALLE",(0,r.kt)("sup",{parentName:"h4",id:"fnref-21"},(0,r.kt)("a",{parentName:"sup",href:"#fn-21",className:"footnote-ref"},"21"))," \ud83d\udd35"),(0,r.kt)("h2",{id:"soft-prompting"},"Soft Prompting"),(0,r.kt)("h4",{id:"soft-promptinglester2021power"},"Soft Prompting",(0,r.kt)("sup",{parentName:"h4",id:"fnref-22"},(0,r.kt)("a",{parentName:"sup",href:"#fn-22",className:"footnote-ref"},"22"))),(0,r.kt)("h4",{id:"interpretable-discretized-soft-promptskhashabi2021prompt"},"Interpretable Discretized Soft Prompts",(0,r.kt)("sup",{parentName:"h4",id:"fnref-23"},(0,r.kt)("a",{parentName:"sup",href:"#fn-23",className:"footnote-ref"},"23"))),(0,r.kt)("h2",{id:"datasets"},"Datasets"),(0,r.kt)("h4",{id:"gsm8kcobbe2021training-"},"GSM8K",(0,r.kt)("sup",{parentName:"h4",id:"fnref-24"},(0,r.kt)("a",{parentName:"sup",href:"#fn-24",className:"footnote-ref"},"24"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"hotpotqayang2018hotpotqa-"},"HotPotQA",(0,r.kt)("sup",{parentName:"h4",id:"fnref-25"},(0,r.kt)("a",{parentName:"sup",href:"#fn-25",className:"footnote-ref"},"25"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"feverthorne2018fever-"},"Fever",(0,r.kt)("sup",{parentName:"h4",id:"fnref-26"},(0,r.kt)("a",{parentName:"sup",href:"#fn-26",className:"footnote-ref"},"26"))," \ud83d\udd35"),(0,r.kt)("h2",{id:"image-prompt-engineering"},"Image Prompt Engineering"),(0,r.kt)("h4",{id:"taxonomy-of-prompt-modifiersoppenlaender2022taxonomy"},"Taxonomy of prompt modifiers",(0,r.kt)("sup",{parentName:"h4",id:"fnref-27"},(0,r.kt)("a",{parentName:"sup",href:"#fn-27",className:"footnote-ref"},"27"))),(0,r.kt)("h4",{id:"diffusiondbwang2022diffusiondb"},"DiffusionDB",(0,r.kt)("sup",{parentName:"h4",id:"fnref-28"},(0,r.kt)("a",{parentName:"sup",href:"#fn-28",className:"footnote-ref"},"28"))),(0,r.kt)("h2",{id:"prompt-engineering-ides"},"Prompt Engineering IDEs"),(0,r.kt)("h4",{id:"prompt-idestrobelt2022promptide-"},"Prompt IDE",(0,r.kt)("sup",{parentName:"h4",id:"fnref-29"},(0,r.kt)("a",{parentName:"sup",href:"#fn-29",className:"footnote-ref"},"29"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"prompt-sourcebach2022promptsource-"},"Prompt Source",(0,r.kt)("sup",{parentName:"h4",id:"fnref-30"},(0,r.kt)("a",{parentName:"sup",href:"#fn-30",className:"footnote-ref"},"30"))," \ud83d\udd35"),(0,r.kt)("h2",{id:"applied-prompt-engineering"},"Applied Prompt Engineering"),(0,r.kt)("h4",{id:"language-model-cascadesdohan2022language"},"Language Model Cascades",(0,r.kt)("sup",{parentName:"h4",id:"fnref-31"},(0,r.kt)("a",{parentName:"sup",href:"#fn-31",className:"footnote-ref"},"31"))),(0,r.kt)("h4",{id:"mrklkarpas2022mrkl-"},"MRKL",(0,r.kt)("sup",{parentName:"h4",id:"fnref-32"},(0,r.kt)("a",{parentName:"sup",href:"#fn-32",className:"footnote-ref"},"32"))," \ud83d\udd35"),(0,r.kt)("h4",{id:"reactyao2022react-"},"ReAct",(0,r.kt)("sup",{parentName:"h4",id:"fnref-33"},(0,r.kt)("a",{parentName:"sup",href:"#fn-33",className:"footnote-ref"},"33"))," \ud83d\udd35"),(0,r.kt)("h2",{id:"user-interface-design"},"User Interface Design"),(0,r.kt)("h4",{id:"design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design"},"Design Guidelines for Prompt Engineering Text-to-Image Generative Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-34"},(0,r.kt)("a",{parentName:"sup",href:"#fn-34",className:"footnote-ref"},"34"))),(0,r.kt)("h2",{id:"prompt-injection"},"Prompt Injection"),(0,r.kt)("h4",{id:"machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine"},"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods",(0,r.kt)("sup",{parentName:"h4",id:"fnref-35"},(0,r.kt)("a",{parentName:"sup",href:"#fn-35",className:"footnote-ref"},"35"))),(0,r.kt)("h2",{id:"surveys"},"Surveys"),(0,r.kt)("h4",{id:"pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain"},"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",(0,r.kt)("sup",{parentName:"h4",id:"fnref-36"},(0,r.kt)("a",{parentName:"sup",href:"#fn-36",className:"footnote-ref"},"36"))),(0,r.kt)("h2",{id:"miscl"},"Miscl"),(0,r.kt)("h4",{id:"learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning"},"Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-37"},(0,r.kt)("a",{parentName:"sup",href:"#fn-37",className:"footnote-ref"},"37"))),(0,r.kt)("h4",{id:"super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions"},"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",(0,r.kt)("sup",{parentName:"h4",id:"fnref-38"},(0,r.kt)("a",{parentName:"sup",href:"#fn-38",className:"footnote-ref"},"38"))),(0,r.kt)("h4",{id:"making-pre-trained-language-models-better-few-shot-learnersgao2021making"},"Making Pre-trained Language Models Better Few-shot Learners",(0,r.kt)("sup",{parentName:"h4",id:"fnref-39"},(0,r.kt)("a",{parentName:"sup",href:"#fn-39",className:"footnote-ref"},"39"))),(0,r.kt)("h4",{id:"grounding-with-search-resultslivin2022large"},"Grounding with search results",(0,r.kt)("sup",{parentName:"h4",id:"fnref-40"},(0,r.kt)("a",{parentName:"sup",href:"#fn-40",className:"footnote-ref"},"40"))),(0,r.kt)("h4",{id:"how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt"},"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-41"},(0,r.kt)("a",{parentName:"sup",href:"#fn-41",className:"footnote-ref"},"41"))),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-3"},"Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-4"},"Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., & Chen, W. (2021). What Makes Good In-Context Examples for GPT-3?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-4",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-5"},"Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2021). Generated Knowledge Prompting for Commonsense Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-5",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-6"},"Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., & Zettlemoyer, L. (2022). Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-6",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-7"},"Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., & Odena, A. (2021). Show Your Work: Scratchpads for Intermediate Computation with Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-7",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-8"},"Ye, X., & Durrett, G. (2022). The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-8",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-9"},"Si, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber, J., & Wang, L. (2022). Prompting GPT-3 To Be Reliable.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-9",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-10"},"Li, Y., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., & Chen, W. (2022). On the Advance of Making Language Models Better Reasoners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-10",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-11"},"Zhao, T. Z., Wallace, E., Feng, S., Klein, D., & Singh, S. (2021). Calibrate Before Use: Improving Few-Shot Performance of Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-11",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-12"},"Mitchell, E., Noh, J. J., Li, S., Armstrong, W. S., Agarwal, A., Liu, P., Finn, C., & Manning, C. D. (2022). Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-12",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-13"},"Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., & Singh, S. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/v1/2020.emnlp-main.346\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-13",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-14"},"Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2022). Large Language Models Are Human-Level Prompt Engineers.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-14",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-15"},"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., \u2026 Amodei, D. (2020). Language Models are Few-Shot Learners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-15",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-16"},"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., & Lowe, R. (2022). Training language models to follow instructions with human feedback.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-16",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-17"},"Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., \u2026 Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-17",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-18"},"Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili\u0107, S., Hesslow, D., Castagn\xe9, R., Luccioni, A. S., Yvon, F., Gall\xe9, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., Sagot, B., Muennighoff, N., del Moral, A. V., \u2026 Wolf, T. (2022). BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-18",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-19"},"Lieber, O., Sharir, O., Lentz, B., & Shoham, Y. (2021). Jurassic-1: Technical Details and Evaluation, White paper, AI21 Labs, 2021. URL: Https://Uploads-Ssl. Webflow. Com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_ Tech_paper. Pdf.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-19",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-20"},"Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2021). High-Resolution Image Synthesis with Latent Diffusion Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-20",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-21"},"Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., & Chen, M. (2022). Hierarchical Text-Conditional Image Generation with CLIP Latents.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-21",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-22"},"Lester, B., Al-Rfou, R., & Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-22",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-23"},"Khashabi, D., Lyu, S., Min, S., Qin, L., Richardson, K., Welleck, S., Hajishirzi, H., Khot, T., Sabharwal, A., Singh, S., & Choi, Y. (2021). Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-23",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-24"},"Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training Verifiers to Solve Math Word Problems.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-24",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-25"},"Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., & Manning, C. D. (2018). HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-25",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-26"},"Thorne, J., Vlachos, A., Christodoulopoulos, C., & Mittal, A. (2018). FEVER: a large-scale dataset for Fact Extraction and VERification.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-26",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-27"},"Oppenlaender, J. (2022). A Taxonomy of Prompt Modifiers for Text-To-Image Generation.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-27",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-28"},"Wang, Z. J., Montoya, E., Munechika, D., Yang, H., Hoover, B., & Chau, D. H. (2022). DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-28",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-29"},"Strobelt, H., Webson, A., Sanh, V., Hoover, B., Beyer, J., Pfister, H., & Rush, A. M. (2022). Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models. arXiv. https://doi.org/10.48550/ARXIV.2208.07852\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-29",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-30"},"Bach, S. H., Sanh, V., Yong, Z.-X., Webson, A., Raffel, C., Nayak, N. V., Sharma, A., Kim, T., Bari, M. S., Fevry, T., Alyafeai, Z., Dey, M., Santilli, A., Sun, Z., Ben-David, S., Xu, C., Chhablani, G., Wang, H., Fries, J. A., \u2026 Rush, A. M. (2022). PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-30",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-31"},"Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., Lopes, R. G., Wu, Y., Michalewski, H., Saurous, R. A., Sohl-dickstein, J., Murphy, K., & Sutton, C. (2022). Language Model Cascades.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-31",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-32"},"Karpas, E., Abend, O., Belinkov, Y., Lenz, B., Lieber, O., Ratner, N., Shoham, Y., Bata, H., Levine, Y., Leyton-Brown, K., Muhlgay, D., Rozen, N., Schwartz, E., Shachaf, G., Shalev-Shwartz, S., Shashua, A., & Tenenholtz, M. (2022). MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-32",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-33"},"Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022). ReAct: Synergizing Reasoning and Acting in Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-33",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-34"},"Liu, V., & Chilton, L. B. (2022). Design Guidelines for Prompt Engineering Text-to-Image Generative Models. Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491102.3501825\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-34",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-35"},"Crothers, E., Japkowicz, N., & Viktor, H. (2022). Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-35",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-36"},"Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2022). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys. https://doi.org/10.1145/3560815\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-36",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-37"},"Bursztyn, V. S., Demeter, D., Downey, D., & Birnbaum, L. (2022). Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-37",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-38"},"Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G., Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia, K., Doshi, K., Patel, M., \u2026 Khashabi, D. (2022). Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-38",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-39"},"Gao, T., Fisch, A., & Chen, D. (2021). Making Pre-trained Language Models Better Few-shot Learners. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). https://doi.org/10.18653/v1/2021.acl-long.295\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-39",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-40"},"Li\xe9vin, V., Hother, C. E., & Winther, O. (2022). Can large language models reason about medical questions?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-40",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-41"},"Dang, H., Mecke, L., Lehmann, F., Goller, S., & Buschek, D. (2022). How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-41",className:"footnote-backref"},"\u21a9")))))}m.isMDXComponent=!0}}]);