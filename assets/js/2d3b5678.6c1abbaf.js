"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[833],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>u});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var p=n.createContext({}),l=function(e){var t=n.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=l(e.components);return n.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,p=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),f=l(r),u=o,d=f["".concat(p,".").concat(u)]||f[u]||m[u]||a;return r?n.createElement(d,i(i({ref:t},c),{},{components:r})):n.createElement(d,i({ref:t},c))}));function u(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=f;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var l=2;l<a;l++)i[l]=r[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}f.displayName="MDXCreateElement"},7691:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>f,frontMatter:()=>i,metadata:()=>p,toc:()=>c});var n=r(7462),o=(r(7294),r(3905));const a=r.p+"assets/images/prompt_tuning-c6ca2065dd8c0e4671b2091eeb82aca2.png",i={sidebar_position:1},s="Soft Prompting",p={unversionedId:"trainable/soft_prompting",id:"trainable/soft_prompting",title:"Soft Prompting",description:"Soft prompting(@lester2021power) is a model training technique which freezes the model weights,",source:"@site/docs/trainable/soft_prompting.md",sourceDirName:"trainable",slug:"/trainable/soft_prompting",permalink:"/docs/trainable/soft_prompting",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v0.0.2/docs/trainable/soft_prompting.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Trainable \ud83d\udea7",permalink:"/docs/category/trainable-"},next:{title:"Images \ud83d\udea7",permalink:"/docs/category/images-"}},l={},c=[],m={toc:c};function f(e){let{components:t,...r}=e;return(0,o.kt)("wrapper",(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"soft-prompting"},"Soft Prompting"),(0,o.kt)("p",null,"Soft prompting",(0,o.kt)("sup",{parentName:"p",id:"fnref-1"},(0,o.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," is a model training technique which freezes the model weights,\nand instead updates the parameters of a prompt (tunes the prompts)."),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("img",{src:a,style:{width:"500px"}})),(0,o.kt)("p",null,"To understand the logic behind soft prompting, let's think about how ",(0,o.kt)("strong",{parentName:"p"},"model inference")," works:"),(0,o.kt)("p",null,"1) Let's consider how a standard prompt is tokenized:\n",(0,o.kt)("inlineCode",{parentName:"p"},"What's 2+2?")," -> ",(0,o.kt)("inlineCode",{parentName:"p"},"What, 's, 2, +, 2, ?"),". "),(0,o.kt)("p",null,"2) Then, each token will be converted to a vector of values."),(0,o.kt)("p",null,"In model tuning, multiple"),(0,o.kt)("p",null,"This vectors of values can be then considered to be parameters. The model can be further\ntrained, only adjusting the weights of these prompts."),(0,o.kt)("p",null,"Note that as soon as we start updating these weights, the vectors of the tokens no\nlonger correspond to actual embeddings from the vocabulary."),(0,o.kt)("p",null,"Prompt tuning performs better with larger models. Larger models also require less\ntokens. Regardless, more than 20 tokens does not yield significant performance gains."),(0,o.kt)("p",null,"\ud83d\udea7 Under Construction \ud83d\udea7"),(0,o.kt)("div",{className:"footnotes"},(0,o.kt)("hr",{parentName:"div"}),(0,o.kt)("ol",{parentName:"div"},(0,o.kt)("li",{parentName:"ol",id:"fn-1"},"Lester, B., Al-Rfou, R., & Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.\n",(0,o.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")))))}f.isMDXComponent=!0}}]);