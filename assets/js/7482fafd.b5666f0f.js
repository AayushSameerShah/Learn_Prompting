"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[6233],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>d});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function p(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var i=r.createContext({}),l=function(e){var t=r.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):p(p({},t),e)),a},m=function(e){var t=l(e.components);return r.createElement(i.Provider,{value:t},e.children)},f={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,i=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=l(a),d=n,u=c["".concat(i,".").concat(d)]||c[d]||f[d]||o;return a?r.createElement(u,p(p({ref:t},m),{},{components:a})):r.createElement(u,p({ref:t},m))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,p=new Array(o);p[0]=c;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s.mdxType="string"==typeof e?e:n,p[1]=s;for(var l=2;l<o;l++)p[l]=a[l];return r.createElement.apply(null,p)}return r.createElement.apply(null,a)}c.displayName="MDXCreateElement"},9117:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>p,default:()=>f,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var r=a(7462),n=(a(7294),a(3905));const o={sidebar_position:2},p='A "Standard" Prompt',s={unversionedId:"basics/standard_prompt",id:"basics/standard_prompt",title:'A "Standard" Prompt',description:"We have heard of a few different formats of prompts thus far.",source:"@site/docs/basics/standard_prompt.md",sourceDirName:"basics",slug:"/basics/standard_prompt",permalink:"/docs/basics/standard_prompt",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v0.0.2/docs/basics/standard_prompt.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"More on Prompting",permalink:"/docs/basics/more_on_prompting"},next:{title:"Chain of Thought Prompting",permalink:"/docs/basics/chain_of_thought"}},i={},l=[{value:"Few Shot Standard Prompts",id:"few-shot-standard-prompts",level:2}],m={toc:l};function f(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"a-standard-prompt"},'A "Standard" Prompt'),(0,n.kt)("p",null,"We have heard of a few different formats of prompts thus far.\nFollowing Kojima et al.",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),', we will refer to prompts that consist\nsolely of a question as "standard" prompts. We also consider prompts that consist solely of\na question and in the QA format to be "standard" prompts.'),(0,n.kt)("p",null,"Two examples of standard prompts:"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Standard Prompt")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"What is the capital of France?\n")),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Standard Prompt in QA format")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"Q: What is the capital of France?\n\nA:\n")),(0,n.kt)("h2",{id:"few-shot-standard-prompts"},"Few Shot Standard Prompts"),(0,n.kt)("p",null,"Few shot standard prompts",(0,n.kt)("sup",{parentName:"p",id:"fnref-2"},(0,n.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2"))," are just standard prompts that have ",(0,n.kt)("em",{parentName:"p"},"exemplars"),"\nin them. Exemplars are examples of the task that the prompt is trying to solve,\nwhich are included in the prompt itself",(0,n.kt)("sup",{parentName:"p",id:"fnref-3"},(0,n.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3")),". Few shot standard prompts\nare sometimes referred to as standard prompts."),(0,n.kt)("p",null,"Two examples of few shot standard prompts:"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Standard Few Shot Prompt")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"What is the capital of Spain?\nMadrid\nWhat is the capital of Italy?\nRome\nWhat is the capital of France?\n")),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Standard Few Shot Prompt in QA format")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"Q: What is the capital of Spain?\nA: Madrid\nQ: What is the capital of Italy?\nA: Rome\nQ: What is the capital of France?\nA:\n")),(0,n.kt)("p",null,'Few shot prompts facilitate "few shot" AKA "in context" learning, which is the\nability to learn without parameter updates',(0,n.kt)("sup",{parentName:"p",id:"fnref-4"},(0,n.kt)("a",{parentName:"sup",href:"#fn-4",className:"footnote-ref"},"4")),"."),(0,n.kt)("p",null,"We will mainly refer to standard prompts in contrast to new types of prompts we\ndiscuss throughout this course."),(0,n.kt)("div",{className:"footnotes"},(0,n.kt)("hr",{parentName:"div"}),(0,n.kt)("ol",{parentName:"div"},(0,n.kt)("li",{parentName:"ol",id:"fn-1"},"Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-2"},"Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2022). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys. https://doi.org/10.1145/3560815\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-3"},"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-4"},"Zhao, T. Z., Wallace, E., Feng, S., Klein, D., & Singh, S. (2021). Calibrate Before Use: Improving Few-Shot Performance of Language Models.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-4",className:"footnote-backref"},"\u21a9")))))}f.isMDXComponent=!0}}]);