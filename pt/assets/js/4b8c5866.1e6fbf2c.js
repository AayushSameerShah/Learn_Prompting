"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[1758],{3905:(e,a,o)=>{o.d(a,{Zo:()=>d,kt:()=>f});var t=o(67294);function n(e,a,o){return a in e?Object.defineProperty(e,a,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[a]=o,e}function r(e,a){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),o.push.apply(o,t)}return o}function i(e){for(var a=1;a<arguments.length;a++){var o=null!=arguments[a]?arguments[a]:{};a%2?r(Object(o),!0).forEach((function(a){n(e,a,o[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(o,a))}))}return e}function m(e,a){if(null==e)return{};var o,t,n=function(e,a){if(null==e)return{};var o,t,n={},r=Object.keys(e);for(t=0;t<r.length;t++)o=r[t],a.indexOf(o)>=0||(n[o]=e[o]);return n}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)o=r[t],a.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var s=t.createContext({}),p=function(e){var a=t.useContext(s),o=a;return e&&(o="function"==typeof e?e(a):i(i({},a),e)),o},d=function(e){var a=p(e.components);return t.createElement(s.Provider,{value:a},e.children)},l="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},u=t.forwardRef((function(e,a){var o=e.components,n=e.mdxType,r=e.originalType,s=e.parentName,d=m(e,["components","mdxType","originalType","parentName"]),l=p(o),u=n,f=l["".concat(s,".").concat(u)]||l[u]||c[u]||r;return o?t.createElement(f,i(i({ref:a},d),{},{components:o})):t.createElement(f,i({ref:a},d))}));function f(e,a){var o=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var r=o.length,i=new Array(r);i[0]=u;var m={};for(var s in a)hasOwnProperty.call(a,s)&&(m[s]=a[s]);m.originalType=e,m[l]="string"==typeof e?e:n,i[1]=m;for(var p=2;p<r;p++)i[p]=o[p];return t.createElement.apply(null,i)}return t.createElement.apply(null,o)}u.displayName="MDXCreateElement"},87959:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>d,contentTitle:()=>s,default:()=>f,frontMatter:()=>m,metadata:()=>p,toc:()=>l});var t=o(87462),n=(o(67294),o(3905));const r=o.p+"assets/images/chain_of_thought_example-37c925a2720c9c4bb4c823d237bc72c8.png",i=o.p+"assets/images/prompted_palm-20fba06418ed8569b51f0dd376c03b41.png",m={sidebar_position:3,locale:"pt-br",style:"chicago"},s="\ud83d\udfe2 Prompting com Cadeia de Pensamento",p={unversionedId:"intermediate/chain_of_thought",id:"intermediate/chain_of_thought",title:"\ud83d\udfe2 Prompting com Cadeia de Pensamento",description:"Prompting com Cadeia de Pensamento (CdP) (@wei2022chain) \xe9 um m\xe9todo de prompting recente, que encoraja ao LLM (Grande Modelo de Linguagem) a explicar o seu racioc\xednio. A imagem abaixo (@wei2022chain) mostra um prompt few shot padr\xe3o (esquerda) comparado ao prompt com Cadeia de Pensamento (direita).",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/intermediate/chain_of_thought.md",sourceDirName:"intermediate",slug:"/intermediate/chain_of_thought",permalink:"/pt/docs/intermediate/chain_of_thought",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.2/docs/intermediate/chain_of_thought.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,locale:"pt-br",style:"chicago"},sidebar:"tutorialSidebar",previous:{title:"\ud83e\uddd9\u200d\u2642\ufe0f Intermediate",permalink:"/pt/docs/category/\ufe0f-intermediate"},next:{title:"\ud83d\udfe2 Zero Shot Chain of Thought",permalink:"/pt/docs/intermediate/zero_shot_cot"}},d={},l=[{value:"Exemplo",id:"exemplo",level:2},{value:"Incorreto",id:"incorreto",level:4},{value:"Correto",id:"correto",level:4},{value:"Resultados",id:"resultados",level:2},{value:"Limita\xe7\xf5es",id:"limita\xe7\xf5es",level:2},{value:"Observa\xe7\xf5es",id:"observa\xe7\xf5es",level:2}],c={toc:l},u="wrapper";function f(e){let{components:a,...o}=e;return(0,n.kt)(u,(0,t.Z)({},c,o,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"-prompting-com-cadeia-de-pensamento"},"\ud83d\udfe2 Prompting com Cadeia de Pensamento"),(0,n.kt)("p",null,"Prompting com Cadeia de Pensamento (CdP)",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," \xe9 um m\xe9todo de ",(0,n.kt)("em",{parentName:"p"},"prompting")," recente, que encoraja ao ",(0,n.kt)("em",{parentName:"p"},"LLM")," (Grande Modelo de Linguagem) a explicar o seu racioc\xednio. A imagem abaixo",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," mostra um ",(0,n.kt)("em",{parentName:"p"},"prompt few shot")," padr\xe3o (esquerda) comparado ao ",(0,n.kt)("em",{parentName:"p"},"prompt")," com Cadeia de Pensamento (direita)."),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:r,style:{width:"750px"}})),(0,n.kt)("div",{style:{textAlign:"center"}},"Prompt comum x Cadeia de Pensamento (Wei et al.) [em ing\xeas]"),(0,n.kt)("p",null,"A principal ideia da Cadeia de Pensamento (CdP) \xe9 mostrar ao ",(0,n.kt)("em",{parentName:"p"},"LLM")," alguns exemplares ",(0,n.kt)("em",{parentName:"p"},"few shot")," em que o processo de racioc\xednio \xe9 explicado, fazendo com que o ",(0,n.kt)("em",{parentName:"p"},"LLM")," fa\xe7a o mesmo quando der uma resposta ao ",(0,n.kt)("em",{parentName:"p"},"prompt"),". A explica\xe7\xe3o do racioc\xednio frequentemente produz resultados mais apurados."),(0,n.kt)("h2",{id:"exemplo"},"Exemplo"),(0,n.kt)("p",null,"Aqui est\xe3o algumas demonstra\xe7\xf5es. A primeira mostra o GPT-3 (davinci-003) falhando ao resolver um problema simples. A segunda, por sua vez, mostra o GPT-3 (davinci-003)\nobtendo \xeaxito na resolu\xe7\xe3o do mesmo problema, com o uso da t\xe9cnica de Cadeia de Pensamento (CdP)."),(0,n.kt)("h4",{id:"incorreto"},"Incorreto"),(0,n.kt)("div",{"trydyno-embed":"","openai-model":"text-davinci-003","initial-prompt":"Considerando as op\xe7\xf5es abaixo, qual \xe9 a forma mais r\xe1pida de chegar ao trabalho?\\nOp\xe7\xe3o 1: pegue um \xf4nibus de 1000 minutos, depois um trem de meia hora e, finalmente, um passeio de bicicleta de 10 minutos.\\nOp\xe7\xe3o 2: pegue um \xf4nibus de 800 minutos, depois uma hora de trem e, finalmente, um passeio de bicicleta de 30 minutos.","initial-response":"Op\xe7\xe3o 1.","max-tokens":"256","box-rows":"7","model-temp":"0","top-p":"0"}),(0,n.kt)("h4",{id:"correto"},"Correto"),(0,n.kt)("div",{"trydyno-embed":"","openai-model":"text-davinci-003","initial-prompt":"Considerando as op\xe7\xf5es abaixo, qual \xe9 a forma mais r\xe1pida de chegar ao trabalho?\\nOp\xe7\xe3o 1: pegue um \xf4nibus de 10 minutos, depois um \xf4nibus de 40 minutos e, finalmente, um trem de 10 minutos.\\nOp\xe7\xe3o 2: pegue um trem de 90 minutos, depois um passeio de bicicleta de 45 minutos e, finalmente, um \xf4nibus de 10 minutos.\\nA op\xe7\xe3o 1 levar\xe1 10+40+10=60 minutos. A op\xe7\xe3o 2 levar\xe1 90+45+10=145 minutos.\\nComo a op\xe7\xe3o 1 leva 60 minutos e a op\xe7\xe3o 2 leva 145 minutos, a op\xe7\xe3o 1 \xe9 mais r\xe1pida.\\n\\nConsiderando as op\xe7\xf5es abaixo, qual \xe9 a forma mais r\xe1pida de chegar ao trabalho?\\nOp\xe7\xe3o 1: pegue um \xf4nibus de 1000 minutos, depois um trem de meia hora e, finalmente, um passeio de bicicleta de 10 minutos.\\nOp\xe7\xe3o 2: pegue um \xf4nibus de 800 minutos, depois uma hora de trem e, finalmente, um passeio de bicicleta de 30 minutos.","initial-response":"A op\xe7\xe3o 1 levar\xe1 1000+30+10 = 1040 minutos.\nA op\xe7\xe3o 2 levar\xe1 800+60+30 = 890 minutos.\nComo a Op\xe7\xe3o 2 leva 890 minutos e a Op\xe7\xe3o 1 leva 1.040 minutos, a Op\xe7\xe3o 2 \xe9 mais r\xe1pida.","max-tokens":"256","box-rows":"7","model-temp":"0","top-p":"0"}),(0,n.kt)("h2",{id:"resultados"},"Resultados"),(0,n.kt)("p",null,"A Cadeia de Pensamento (CdP) mostrou ser efetiva em melhorar os resultados em tarefas de aritm\xe9tica, senso comum e racic\xednio simb\xf3lico",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),".\nEm particular, ",(0,n.kt)("em",{parentName:"p"},"prompted")," PaLM 540B",(0,n.kt)("sup",{parentName:"p",id:"fnref-2"},(0,n.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2"))," atinge 57% de precis\xe3o na resolu\xe7\xe3o dos problemas de matem\xe1tica da cole\xe7\xe3o de dados GSM8K",(0,n.kt)("sup",{parentName:"p",id:"fnref-3"},(0,n.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3"))," (Estado da Arte, na \xe9poca)."),(0,n.kt)("div",{style:{textAlign:"center"}},(0,n.kt)("img",{src:i,style:{width:"300px"}})),(0,n.kt)("div",{style:{textAlign:"center"}},"Compara\xe7\xe3o de modelos no benchmark GSM8K (Wei et al.) [em ingl\xeas]"),(0,n.kt)("h2",{id:"limita\xe7\xf5es"},"Limita\xe7\xf5es"),(0,n.kt)("p",null,'\xc9 importante ressaltar que, de acordo com Wei et al., "A t\xe9cnica de Cadeia de Pensamento (CdP) s\xf3 produz ganhos no desempenho quando usada em modelos de ~100B de par\xe2metros". Modelos menores escrevem cadeias de pensamentos il\xf3gicas, o que leva a uma piora na precis\xe3o quando comparado ao ',(0,n.kt)("em",{parentName:"p"},"prompt")," padr\xe3o. Comumente, as melhoras obtidas nos ",(0,n.kt)("em",{parentName:"p"},"prompts")," usando a t\xe9cnica de CdP s\xe3o proporcionais ao tamanho do modelo."),(0,n.kt)("h2",{id:"observa\xe7\xf5es"},"Observa\xe7\xf5es"),(0,n.kt)("p",null,"Nenhum modelo de linguagem foi ~ferido~ (leia-se: tunelado) no processo de escrita deste cap\xedtulo \ud83d\ude0a."),(0,n.kt)("div",{className:"footnotes"},(0,n.kt)("hr",{parentName:"div"}),(0,n.kt)("ol",{parentName:"div"},(0,n.kt)("li",{parentName:"ol",id:"fn-1"},"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-2"},"Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., \u2026 Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-3"},"Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training Verifiers to Solve Math Word Problems.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")))))}f.isMDXComponent=!0}}]);